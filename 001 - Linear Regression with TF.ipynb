{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop a linear regression model with TensorFlow\n",
    "### Summary\n",
    "In this project, the final output is a linear regression model with TF. In the process, we will learn the basics of using tensorflow including: creating, running, saving, visualizing smiple computationl graphs and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S1: Creating First Graph and Running it in a Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name='x')\n",
    "y = tf.Variable(4, name='y')\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results of this 1st computation graph: 42\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(x.initializer)\n",
    "    sess.run(y.initializer)\n",
    "    result = sess.run(f)\n",
    "\n",
    "msg = \"results of this 1st computation graph: {}\".format(result)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**: The typical process to accomplish a computation with TF includes following steps: 1) creating entities (variable and computational operations) 2) initialize all defined variables within a TF session 3) execute the computation operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results of this 1st computation graph: 42\n"
     ]
    }
   ],
   "source": [
    "all_var_init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # x.initializer.run()\n",
    "    # y.initializer.run()\n",
    "    all_var_init.run()\n",
    "    result = f.eval()\n",
    "\n",
    "msg = \"results of this 1st computation graph: {}\".format(result)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**: This is a more elegant way to realize the computation graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTICE:** **value node** will not be shared across graph within a session. In contrast, **variable node** will be excuted once and shared across graphs within a single session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S2: Build a linear regression with TF\n",
    "In this section, we are going to implement a linear regression model with TF. In the above section, we had tried to use variable node, which is used to keep a single value. In practice, we need to deal with multi-dimensional array as input, x, which is called **tensor** in TF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 01: Analytical Sollution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.74636536e+01],\n",
       "       [  4.35707688e-01],\n",
       "       [  9.34202131e-03],\n",
       "       [ -1.06593400e-01],\n",
       "       [  6.43945396e-01],\n",
       "       [ -4.25595226e-06],\n",
       "       [ -3.77299124e-03],\n",
       "       [ -4.26701427e-01],\n",
       "       [ -4.40539479e-01]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 02: Generalizing with manually computed Gradient Descents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 , MSE= 891425.0\n",
      "Epoch:  100 , MSE= 891425.0\n",
      "Epoch:  200 , MSE= 891425.0\n",
      "Epoch:  300 , MSE= 891425.0\n",
      "Epoch:  400 , MSE= 891425.0\n",
      "Epoch:  500 , MSE= 891425.0\n",
      "Epoch:  600 , MSE= 891425.0\n",
      "Epoch:  700 , MSE= 891425.0\n",
      "Epoch:  800 , MSE= 891425.0\n",
      "Epoch:  900 , MSE= 891425.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.36162186e+01],\n",
       "       [  5.63680878e+01],\n",
       "       [  3.69787903e+02],\n",
       "       [  7.65920792e+01],\n",
       "       [  1.63969841e+01],\n",
       "       [  3.43656406e+04],\n",
       "       [  5.59711838e+01],\n",
       "       [  5.15148132e+02],\n",
       "       [ -1.73368848e+03]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# add an operation to scale the housing input data\n",
    "scaled_housing_plus_bias = housing_data_plus_bias\n",
    "X = tf.constant(scaled_housing_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "error = y_pred - y\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "gradient = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradient)\n",
    "\n",
    "all_var_init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(all_var_init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: \", epoch, \", MSE=\", mse.eval())\n",
    "            \n",
    "    sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 03: Implement linear regression with optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# add an operation to scale the housing input data\n",
    "scaled_housing_plus_bias = housing_data_plus_bias\n",
    "X = tf.constant(scaled_housing_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "# gradient = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "# training_op = tf.assign(theta, theta - learning_rate * gradient)\n",
    "optimizor = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizor.minimize(mse)\n",
    "\n",
    "all_var_init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(all_var_init)            \n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            save_path = saver.save(sess, './tmp/my_model.ckpt')\n",
    "            \n",
    "        sess.run(training_op)\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, './tmp/my_model_final.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint                              my_model_final.ckpt.data-00000-of-00001\r\n",
      "my_model.ckpt.data-00000-of-00001       my_model_final.ckpt.index\r\n",
      "my_model.ckpt.index                     my_model_final.ckpt.meta\r\n",
      "my_model.ckpt.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disucssion**: In this section, we implement the linear regression by using TensorFlow's optimizer for cofficients estimation. Additionally, we also use tf.train.Saver() to store the snapshot of trained model in the process. This operation defend us from re-training model from begining after failure in previous training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 04: Linear Regression with TensorBoard for Tracking Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime('%Y%m%d_%H%M%S')\n",
    "root_logdir = 'tf_logs'\n",
    "logdir = './{}/run-{}/'.format(root_logdir, now)\n",
    "\n",
    "# linear regression with TF\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# add an operation to scale the housing input data\n",
    "scaled_housing_plus_bias = housing_data_plus_bias\n",
    "X = tf.constant(scaled_housing_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "optimizor = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizor.minimize(mse)\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "all_var_init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(all_var_init)            \n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            save_path = saver.save(sess, './tmp/my_model.ckpt')\n",
    "        \n",
    "        summary_str = mse_summary.eval()\n",
    "        file_writer.add_summary(summary_str, epoch)\n",
    "        sess.run(training_op)\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, './tmp/my_model_final.ckpt')\n",
    "    \n",
    "# close log writer\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mrun-20170515_043800\u001b[m\u001b[m \u001b[34mrun-20170515_043858\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls tf_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n",
      "drwxr-xr-x@ 3 yizhang  staff  102 May 14 21:38 \u001b[34mrun-20170515_043800\u001b[m\u001b[m\r\n",
      "drwxr-xr-x@ 3 yizhang  staff  102 May 14 21:38 \u001b[34mrun-20170515_043858\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l tf_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorBoard Practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    with tf.variable_scope('relu', reuse=True):\n",
    "        threshold = tf.get_variable('threshold')\n",
    "    \n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
    "        b = tf.Variable(0.0, name='bias')\n",
    "        z = tf.add(tf.matmul(X, w), b, name='z')\n",
    "        return(tf.maximum(z, threshold, name='relu'))\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "with tf.variable_scope('relu'):\n",
    "    threshold = tf.get_variable('threshold', \n",
    "                                shape=(), \n",
    "                                initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_var_init = tf.global_variables_initializer()\n",
    "# saver = tf.train.Saver()\n",
    "# mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(all_var_init)\n",
    "    file_writer.add_summary(summary_str, epoch)\n",
    "    sess.run(training_op)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
